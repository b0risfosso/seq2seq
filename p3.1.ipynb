{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99633c69-7c87-458b-9cb5-b252758fb874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/b/ml/seq2seq/venv/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b03d45f-5719-4d31-9190-8191b427a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "import tqdm\n",
    "import evaluate\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a92f62b9-799c-463c-8f39-f5144a032a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72e64277-7101-490f-9a74-02a5fd93efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset found at bentrevett/multi30k\n",
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9efcdf9d-d777-4aaa-8399-1cc73950964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "626ecf92-0a74-47f1-ac58-c87e25524fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebccd5a8-55ff-44d7-816a-0df256e3b61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76beeeb8aa2c4dc281002128f4b69f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd435a10df546a286985e48f4685671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16b715db1c9485e8b783e5ca1f54805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 1000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"de_nlp\": de_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0852ff91-c4d4-4bf0-b15a-4eb5fc9c8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, token_to_index, unk_token=\"<unk>\"):\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {idx:token for token,idx in token_to_index.items()}\n",
    "        self.unk_token = unk_token\n",
    "        self.unk_index = self.token_to_index[unk_token]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token_to_index.get(token, self.unk_index)\n",
    "\n",
    "    def token_to_idx(self, token):\n",
    "        return self.__getitem__(token)\n",
    "\n",
    "    def idx_to_token(self, idx):\n",
    "        return self.index_to_token.get(idx, self.unk_token)\n",
    "\n",
    "    def set_default_index(self, index):\n",
    "        if index==self.unk_index:\n",
    "            return\n",
    "\n",
    "        current_token = self.index_to_token(index, None)\n",
    "\n",
    "        if self.unk_token in self.token_to_index and current_token:\n",
    "            self.token_to_index[self.unk_token], self.token_to_index[current_token] = index, self.unk_index\n",
    "\n",
    "        if self.unk_index in self.index_to_token and index in self.index_to_token:\n",
    "            self.index_to_token[self.unk_index], self.index_to_token[index] = self.index_to_token[index], self.index_to_token[self.unk_index]\n",
    "\n",
    "        self.unk_index = index\n",
    "\n",
    "    def get_itos(self):\n",
    "        return self.index_to_token\n",
    "\n",
    "    def get_stoi(self):\n",
    "        return self.token_to_index\n",
    "\n",
    "    def lookup_indices(self, tokens):\n",
    "        return [self.token_to_idx(token) for token in tokens]\n",
    "\n",
    "    def lookup_tokens(self, indices):\n",
    "        if torch.istensor(indices):\n",
    "            indices = indices.tolist()\n",
    "        \n",
    "        return [self.idx_to_token(index) for index in indices]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "acaf8895-bd19-4d02-82d8-c32a2218089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>': 0, '<pad>': 1, '<sos>': 2, '<eos>': 3, 'death': 4, 'destruction': 5, 'domination': 6, 'weapons': 7, 'graves': 8, 'all': 9, 'you': 10, 'care': 11, 'about': 12, 'is': 13, 'love': 14}\n",
      "domination\n"
     ]
    }
   ],
   "source": [
    "def build_vocab_from_iterator(iterator, min_freq=1, specials=None):\n",
    "    counter = Counter()\n",
    "    for token in iterator:\n",
    "        counter.update(token)\n",
    "\n",
    "    token_to_index = {}\n",
    "    if specials:\n",
    "        for idx, token in enumerate(specials):\n",
    "            token_to_index[token] = idx\n",
    "\n",
    "    for token, freq in counter.items():\n",
    "        if freq >= min_freq and token not in token_to_index:\n",
    "            token_to_index[token] = len(token_to_index)\n",
    "\n",
    "    unk_token = specials[0] if specials else \"<unk>\"\n",
    "    if unk_token not in token_to_index:\n",
    "        token_to_index[unk_token] = len(token_to_index)\n",
    "\n",
    "    return Vocab(token_to_index, unk_token=unk_token)\n",
    "\n",
    "\n",
    "tokens = [[\"death\", \"destruction\", \"domination\", \"weapons\", \"graves\"], [\"all\", \"you\", \"care\", \"about\", \"is\", \"love\"]]\n",
    "min_freq = 1\n",
    "specials = [\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"]\n",
    "vocab = build_vocab_from_iterator(tokens, min_freq, specials)\n",
    "print(vocab.get_stoi())\n",
    "print(vocab.idx_to_token(6))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc3694c4-9f8a-4e92-826a-6cedf94d78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "de_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60466b26-0417-4b73-ac5d-9cb8a9d28a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
    "assert de_vocab[pad_token] == en_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68f81f14-b722-4864-8472-8d24bb3e22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "de_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9ff08779-1201-49b2-85b2-a13314cc1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1a5331c8-54d2-4e67-8b06-b5a66be796f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa44d5d945c49d2b0ce74c06d2dd74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102d10a9df3f426ca3fc02ac7bc6ef73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"de_vocab\": de_vocab}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f7349a8-7fc3-4b4a-8238-f93bf1e06532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5287a085-7719-4436-b445-e903e430cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5180f8f0-5a06-4be9-be24-440682107900",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "vaild_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1b87d33-abe8-48ab-a3b7-53095c5960ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(\n",
    "            self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        )\n",
    "        return outputs, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031939c-6c8b-4553-8c4b-c10d9de97af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, encoder hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        # outputs are always from the last layer\n",
    "        # hidden [-2, :, :] is the last of the forwards RNN\n",
    "        # hidden [-1, :, :] is the last of the backwards RNN\n",
    "        # initial decoder hidden is final hidden state of the forwards and backwards\n",
    "        # encoder RNNs are fed through a linear layer\n",
    "        hidden = torch.tanh(\n",
    "            self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        )\n",
    "        # outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        # hidden = [batch size, decoder hidden dim]\n",
    "        return outputs, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c845d45-1a1e-46be-a7ba-a442f26150aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
