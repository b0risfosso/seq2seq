{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99633c69-7c87-458b-9cb5-b252758fb874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/b/ml/seq2seq/venv/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b03d45f-5719-4d31-9190-8191b427a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "import tqdm\n",
    "import evaluate\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92f62b9-799c-463c-8f39-f5144a032a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e64277-7101-490f-9a74-02a5fd93efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset found at bentrevett/multi30k\n",
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efcdf9d-d777-4aaa-8399-1cc73950964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626ecf92-0a74-47f1-ac58-c87e25524fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebccd5a8-55ff-44d7-816a-0df256e3b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"de_nlp\": de_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0852ff91-c4d4-4bf0-b15a-4eb5fc9c8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, token_to_index, unk_token=\"<unk>\"):\n",
    "        self.token_to_index = token_to_index\n",
    "        self.index_to_token = {idx:token for token,idx in token_to_index.items()}\n",
    "        self.unk_token = unk_token\n",
    "        self.unk_index = token_to_index[unk_token]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_to_index)\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return self.token_to_index.get(token, self.unk_index)\n",
    "\n",
    "    def token_to_idx(self, token):\n",
    "        return self.__getitem__(token)\n",
    "\n",
    "    def idx_to_token(self, index):\n",
    "        return self.index_to_token.get(index, self.unk_token)\n",
    "\n",
    "    def set_default_token(self, index):\n",
    "        if index == self.unk_index:\n",
    "            return\n",
    "\n",
    "        current_token = self.index_to_token.get(index, None)\n",
    "\n",
    "        if self.unk_token in self.token_to_index and current_token:\n",
    "            self.token_to_index[self.unk_token], self.token_to_index[current_token] = index, self.unk_index\n",
    "\n",
    "        if self.unk_index in self.index_to_token and index in self.index_to_token:\n",
    "            self.index_to_token[self.unk_index], self.index_to_token[index] = self.index_to_token[index], self.index_to_token[self.unk_index]\n",
    "\n",
    "        self.unk_index = index\n",
    "\n",
    "    def get_stoi(self):\n",
    "        return self.token_to_index\n",
    "\n",
    "    def get_itos(self):\n",
    "        return self.index_to_token\n",
    "\n",
    "    def lookup_tokens(self, indices):\n",
    "        if torch.istensor(indices):\n",
    "            indices = indices.tolist()\n",
    "\n",
    "        return [self.idx_to_token(index) for index in indices]\n",
    "\n",
    "    def lookup_indices(self, tokens):\n",
    "        return [self.token_to_idx(token) for token in tokens]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acaf8895-bd19-4d02-82d8-c32a2218089e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>': 0, '<pad>': 1, '<sos>': 2, '<eos>': 3, 'death': 4, 'destruction': 5, 'domination': 6, 'weapons': 7, 'graves': 8, 'all': 9, 'you': 10, 'care': 11, 'about': 12, 'is': 13, 'love': 14}\n",
      "domination\n"
     ]
    }
   ],
   "source": [
    "def build_vocab_from_iterator(iterator, min_freq=1, specials=None):\n",
    "    counter = Counter()\n",
    "    for token in iterator:\n",
    "        counter.update(token)\n",
    "\n",
    "    token_to_index = {}\n",
    "    if specials:\n",
    "        for idx, token in enumerate(specials):\n",
    "            token_to_index[token] = idx\n",
    "\n",
    "    for token, freq in counter.items():\n",
    "        if freq >= min_freq and token not in token_to_index:\n",
    "            token_to_index[token] = len(token_to_index)\n",
    "\n",
    "    unk_token = specials[0] if specials else \"<unk>\"\n",
    "    if unk_token not in token_to_index:\n",
    "        token_to_index[unk_token] = len(token_to_index)\n",
    "\n",
    "    return Vocab(token_to_index, unk_token=unk_token)\n",
    "\n",
    "\n",
    "tokens = [[\"death\", \"destruction\", \"domination\", \"weapons\", \"graves\"], [\"all\", \"you\", \"care\", \"about\", \"is\", \"love\"]]\n",
    "min_freq = 1\n",
    "specials = [\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"]\n",
    "vocab = build_vocab_from_iterator(tokens, min_freq, specials)\n",
    "print(vocab.get_stoi())\n",
    "print(vocab.idx_to_token(6))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3694c4-9f8a-4e92-826a-6cedf94d78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "de_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60466b26-0417-4b73-ac5d-9cb8a9d28a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
    "assert de_vocab[pad_token] == en_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f81f14-b722-4864-8472-8d24bb3e22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "de_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ff08779-1201-49b2-85b2-a13314cc1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a5331c8-54d2-4e67-8b06-b5a66be796f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"de_vocab\": de_vocab}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b352653a-cf45-46f8-8bec-80254db58841",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f7349a8-7fc3-4b4a-8238-f93bf1e06532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5287a085-7719-4436-b445-e903e430cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5180f8f0-5a06-4be9-be24-440682107900",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "vaild_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b8e260d-3794-4408-b841-25cb1ab2956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional=True)\n",
    "        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, encoder_hidden_dim * 2]\n",
    "        # hidden = [n layers * n directions, batch_size, encoder_hidden_dim]\n",
    "        hidden = torch.tanh(\n",
    "            self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        )\n",
    "        # hidden = [batch size, decoder_hidden_dim]\n",
    "        return outputs, hidden\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cddd8e-779b-4d06-9af3-403930de4975",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAttention\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoder_hidden_dim, decoder_hidden_dim):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn_fc = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim, decoder_hidden_dim\n",
    "        )\n",
    "        self.v_fc = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_length = encoder_outputs.shape[0]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_length, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        energy = torch.tanh(self.attn_fc(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v_fc(energy).squeeze(2)\n",
    "        return softmax(attention, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e6386b-ab8a-4a76-96d8-8c8d04575c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7df445-fb6c-4229-8da1-b36c98319ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDecoder\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      4\u001b[0m         output_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m         dropout\n\u001b[1;32m     10\u001b[0m     ):\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim,\n",
    "        embedding_dim,\n",
    "        encoder_hidden_dim,\n",
    "        decoder_hidden_dim,\n",
    "        attention,\n",
    "        dropout\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU((encoder_hidden_dim * 2), decoder_hidden_dim)\n",
    "        self.fc_out = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim + embedding_hidden_dim, output_dim\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedded(input))\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        hidden = hidden.unsqueeze(0)\n",
    "        output, hidden = self.rnn(torch.cat((embedded, weighted), dim=2), hidden)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        embedded = embedded.squeeze(0)\n",
    "        predictions = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        return predictions, hidden.squeeze(0), a.squeeze(1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afa19c04-fc61-4b29-8e4c-c2848eb25f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        batch_size = src.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_length):\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_forcing else top1\n",
    "        return outputs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "540b36ce-4092-4088-84f0-63e84d4d7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(de_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "encoder_hidden_dim = 512\n",
    "decoder_hidden_dim = 512\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "attention = Attention(encoder_hidden_dim, decoder_hidden_dim)\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim,\n",
    "    decoder_dropout,\n",
    "    attention,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d3ab9d5-b098-481d-b22b-b5110b025fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn_fc): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v_fc): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a553fa6-c9d6-466f-9dd6-0fcadf4175eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model has 20,518,405 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"the model has {count_parameters(model):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56c9f314-d60f-4678-9a1e-841b3dcdf551",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5d7c55e-2b34-43ef-b52f-8cdaa32f545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d17cb6cd-184a-4ad4-acb3-9b5f97cc7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        logging.debug(f\"Processing batch {i}\")\n",
    "        src = batch[\"de_ids\"].to(device)\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bac2ad8e-c3b1-4504-ad61-0ff0d29b154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"de_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            output = model(src, trg, 0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5371e-9625-4a70-bbaa-be11cf9a663b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]DEBUG:root:Processing batch 0\n",
      "DEBUG:root:Processing batch 1\n",
      "DEBUG:root:Processing batch 2\n",
      "DEBUG:root:Processing batch 3\n",
      "DEBUG:root:Processing batch 4\n",
      "DEBUG:root:Processing batch 5\n",
      "DEBUG:root:Processing batch 6\n",
      "DEBUG:root:Processing batch 7\n",
      "DEBUG:root:Processing batch 8\n",
      "DEBUG:root:Processing batch 9\n",
      "DEBUG:root:Processing batch 10\n",
      "DEBUG:root:Processing batch 11\n",
      "DEBUG:root:Processing batch 12\n",
      "DEBUG:root:Processing batch 13\n",
      "DEBUG:root:Processing batch 14\n",
      "DEBUG:root:Processing batch 15\n",
      "DEBUG:root:Processing batch 16\n",
      "DEBUG:root:Processing batch 17\n",
      "DEBUG:root:Processing batch 18\n",
      "DEBUG:root:Processing batch 19\n",
      "DEBUG:root:Processing batch 20\n",
      "DEBUG:root:Processing batch 21\n",
      "DEBUG:root:Processing batch 22\n",
      "DEBUG:root:Processing batch 23\n",
      "DEBUG:root:Processing batch 24\n",
      "DEBUG:root:Processing batch 25\n",
      "DEBUG:root:Processing batch 26\n",
      "DEBUG:root:Processing batch 27\n",
      "DEBUG:root:Processing batch 28\n",
      "DEBUG:root:Processing batch 29\n",
      "DEBUG:root:Processing batch 30\n",
      "DEBUG:root:Processing batch 31\n",
      "DEBUG:root:Processing batch 32\n",
      "DEBUG:root:Processing batch 33\n",
      "DEBUG:root:Processing batch 34\n",
      "DEBUG:root:Processing batch 35\n",
      "DEBUG:root:Processing batch 36\n",
      "DEBUG:root:Processing batch 37\n",
      "DEBUG:root:Processing batch 38\n",
      "DEBUG:root:Processing batch 39\n",
      "DEBUG:root:Processing batch 40\n",
      "DEBUG:root:Processing batch 41\n",
      "DEBUG:root:Processing batch 42\n",
      "DEBUG:root:Processing batch 43\n",
      "DEBUG:root:Processing batch 44\n",
      "DEBUG:root:Processing batch 45\n",
      "DEBUG:root:Processing batch 46\n",
      "DEBUG:root:Processing batch 47\n",
      "DEBUG:root:Processing batch 48\n",
      "DEBUG:root:Processing batch 49\n",
      "DEBUG:root:Processing batch 50\n",
      "DEBUG:root:Processing batch 51\n",
      "DEBUG:root:Processing batch 52\n",
      "DEBUG:root:Processing batch 53\n",
      "DEBUG:root:Processing batch 54\n",
      "DEBUG:root:Processing batch 55\n",
      "DEBUG:root:Processing batch 56\n",
      "DEBUG:root:Processing batch 57\n",
      "DEBUG:root:Processing batch 58\n",
      "DEBUG:root:Processing batch 59\n",
      "DEBUG:root:Processing batch 60\n",
      "DEBUG:root:Processing batch 61\n",
      "DEBUG:root:Processing batch 62\n",
      "DEBUG:root:Processing batch 63\n",
      "DEBUG:root:Processing batch 64\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device\n",
    "    )\n",
    "    if valid_loss < best_valid_loss: \n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"tut3.1-model.pt\")\n",
    "\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "#print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd6d69b-9356-4cae-be89-1cd94d120fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"tut3.1-model.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "# print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbef07-7c2a-4d96-8f88-d1b8a9a467b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"tut3.1-model.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad7a08-cfb6-40c4-99cb-f3a57fdb79a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f49f55a-0254-433e-a81b-046165de666e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
